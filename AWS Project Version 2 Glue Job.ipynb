{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94549ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import cast\n",
    "from pyspark.sql.types import LongType\n",
    "import boto3\n",
    "\n",
    "## @params: [JOB_NAME]\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "#Copying the filename\n",
    "\n",
    "session = boto3.Session()\n",
    "s3 = session.resource('s3')\n",
    "client = boto3.client('s3')\n",
    "response = client.list_objects(Bucket = 'practiseons3')\n",
    "filenames = []\n",
    "for i in range(len(response[\"Contents\"])):\n",
    "    if response['Contents'][i]['Key'].__contains__(\"Archive/\"):\n",
    "        continue\n",
    "    filenames.append(response['Contents'][i]['Key'])\n",
    "\n",
    "# Define the S3 path\n",
    "s3_path = f\"s3://practiseons3/{filenames[0]}\"\n",
    "# df = glueContext.create_dynamic_frame_from_options(\n",
    "#     connection_type=\"s3\",\n",
    "#     connection_options={\"paths\": [s3_path]},\n",
    "#     format=\"json\", transformation_ctx = \"test\")\n",
    "# df.printSchema()\n",
    "\n",
    "spark_df=spark.read.json(s3_path)\n",
    "\n",
    "# Read data from DynamoDB using GluedDataFrame\n",
    "dynamodb_df = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"dynamodb\",\n",
    "    connection_options={\"dynamodb.input.tableName\": \"Financial_Data\",\n",
    "        \"dynamodb.throughput.read.percent\": \"1.0\",\n",
    "        \"dynamodb.splits\": \"100\"\n",
    "    }\n",
    ")\n",
    "\n",
    "logger  = glueContext.get_logger()\n",
    "\n",
    "# logger.info(\"Changing the glue data frame to spark\")\n",
    "# spark_df = df.toDF()\n",
    "\n",
    "logger.info(\"Covert the complaint_id into the Integer format\")\n",
    "spark_df = spark_df.withColumn(\"complaint_id\", col(\"complaint_id\").cast(LongType()))\n",
    "spark_df.show(5)\n",
    "spark_df.printSchema()\n",
    "\n",
    "logger.info(\"Changing the dynamoDB glue data frame to spark\")\n",
    "spark_dynamodb_df = dynamodb_df.toDF()\n",
    "spark_dynamodb_df.show(5)\n",
    "spark_dynamodb_df.printSchema()\n",
    "\n",
    "new_spark_df = None\n",
    "logger.info(\"Joining the two dataframes on complaint ID\")\n",
    "if spark_dynamodb_df.isEmpty():\n",
    "    new_spark_df = spark_df.coalesce(10)\n",
    "else:\n",
    "    new_dynamodb_df = spark_dynamodb_df.select('complaint_id').withColumnRenamed('complaint_id', 'complaint_id_dynamodb')\n",
    "    new_spark_df = spark_df.join(new_dynamodb_df,\n",
    "                            spark_df['complaint_id'] == new_dynamodb_df['complaint_id_dynamodb'], \n",
    "                            how = 'left').where(new_dynamodb_df['complaint_id_dynamodb'].isNull())\n",
    "    new_spark_df.drop('complaint_id_dynamodb')\n",
    "    new_spark_df = new_spark_df.coalesce(10)\n",
    "\n",
    "new_spark_df.show()\n",
    "\n",
    "logger.info(\"Converting the SparkDataframe into GlueDataframe\")\n",
    "glue_df = DynamicFrame.fromDF(new_spark_df, glueContext, \"new_spark_df\")\n",
    "logger.info(\"loading the data into the DynamoDB\")\n",
    "glueContext.write_dynamic_frame.from_options(frame=glue_df, connection_type=\"dynamodb\", connection_options={\n",
    "    \"dynamodb.throughput.write.percent\": 1.0,\n",
    "    \"dynamodb.output.tableName\": \"Financial_Data\"\n",
    "})\n",
    "logger.info(\"Get the file name from S3 object\")\n",
    "\n",
    "logger.info(\"Move the file from S3 to folder named archive\")\n",
    "# Define source and destination paths\n",
    "\n",
    "\n",
    "# Create S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Copy the file\n",
    "response = client.copy_object(Bucket= 'practiseons3', CopySource={'Bucket': 'practiseons3', 'Key': filenames[0]}, Key = f\"Archive/{filenames[0]}\")\n",
    "\n",
    "# Delete the original file (optional)\n",
    "s3_client.delete_object(Bucket=\"practiseons3\", Key=filenames[0])\n",
    "\n",
    "print(\"File moved successfully.\")\n",
    "job.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
